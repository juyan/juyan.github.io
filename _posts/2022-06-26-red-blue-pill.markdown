---
layout: post
title:  "你选红还是蓝药丸?"
date:   2022-06-16 23:38:00 -0700
categories: 个人 疫情
---
# 电影与现实
相信很多人还记得黑客帝国的经典桥段：你选红药丸还是蓝药丸？

- 红药丸：进入便接受残酷的现实世界，人类其实是被机器插着管子的奴隶。人类如同穷寇一般被机器追的东躲西藏，用微弱的力量对抗强大的机器
- 蓝药丸：继续待在机器创造的美好虚拟世界当中，这里衣食无忧，生活幸福。

![红蓝药丸](/assets/red-or-blue-pill.jpg)

虽然仅仅是个1999年的电影里的桥段，这个隐喻却成为了流行文化的一部分被人引用至今。一般来说，红蓝药丸的选择被引申为“接受可能令你三观尽毁的真相”与“将头埋进沙中继续着愚蠢但是安心的无知”之间的选择。这个隐喻时过二十多年却愈发的形象，以至于2021年上映的黑客帝国4将其作为了自己的宣传海报。

这个隐喻如此形象而且流行，背后的原因到底是什么？粗浅的想一下，我们的世界正在一步一步朝着99年沃卓斯基导演设想的未来世界慢慢前进，例如人们的衣食住行都被数字化了（网购，外卖，元宇宙，网约车）。没错，可是这与电影里的世界仍然相去甚远，电影里的AI是在**欺骗**人类的意识和感官，让他们认为他们活在一个美好的世界当中，而不是裸体浑身插着管子泡在营养液里充当AI的电池。

谈到欺骗，我在[欢迎光临]({% post_url 2022-04-24-welcome %})一文中解释道，我最担心与恐惧的是假消息，煽动性与误导性的观点欺骗大批的人类。很不幸的是在这一点上人类似乎也在AI的“帮助”下大踏步地走向深渊。

# 算法
社交媒体与短视频软件都有核心的内容算法去解决“给每个用户推什么内容”的算法。在内容算法成为问题核心之前，它基本上是100%利益驱动的。而显然这些公司的利益和点击量直接挂钩，所以算法会推给你最有可能点开的内容。这有两个问题：
- 假消息，煽动性与误导性的内容往往更能吸引点击量。而算法则会变本加厉地将其传播给更多的用户。也就是说你打开App得到的推送，很有可能是假新闻，或者是别有用心的误导新闻。
- 一旦你的情绪和观点被调动起来，你更有可能点开和自己观点相似或相近的内容，而对自己对立的观点嗤之以鼻，避而远之。那么算法会基本确保你看到的基本上都是一类你赞成的观点，而不会出现另一面的观点。

基于以上两点逻辑，我们不难得出，社交媒体与短视频软件会使你更加懒于思考，而使得你的的观点更加偏颇，极端化。这于己于人都是有害的。赚了红利的就是软件公司，以及那些别有用心地散布不实言论的人。

算法辅助了大量的欺骗，这其实更像是黑客帝国的桥段了。试想一个人整天被算法生产的内容所环绕，那么他很可能会生活在一个“蓝药丸”的世界，所知所想皆为他人别有用心地操纵，以达到某种目的。

# 红药丸
可能有人会问，你怎么保证自己没有生活在“蓝药丸”的世界呢？也许写下这篇文章的作者本人也是被欺骗的人其中之一罢了。我认为有以下几点原则可以遵循。

## 分析Bug
正如黑客帝国里的黑猫隐喻一样，一个不真实的世界很可能是会有缺陷的，逻辑谬误是主要的缺陷之一。我们在初中语文课上就学习过如何分析并质疑论据和结论。如果内容主干是“因为A，B，C所以D”，那我们就可以问自己：“A是否可信？B是否可信？C是否可信？假设A，B，C都可信，是否能得出结论D？“这虽然看似简单，很多红遍全网的内容却无法在这个简单的公式下站得住脚。

## 不同的声音
如果自己分析不出来Bug，也不要急于接受。想一个问题：”哪里能看到质疑或者反对的声音? 这些质疑和反对站得住脚吗？”。 原因也很简单，首先，你一个人无法提出质疑不代表别人无法提出质疑。很多内容具有高度的领域专业性，很可能你根本无法判断其论据的可靠性，但是有人可以。其次，由于领域和视角的复杂性，所有人对一件事情持单一看法是基本不可能的事情，如果没有反对的声音可能暗示话题已经被操纵。

## 多读书，多写字
少刷手机。读书与写字不仅可以积累知识储备，更能让你的大脑活动起来，这些都是进行分析和质疑的基础。

# 怎么做？
良好的开端是成功的一半。为了摆脱机器的魔爪，成为一个独立的灵魂，我建议：
1. 将抖音，快手以及类似软件从你的手机中卸载。如果是植入在现有软件（类似微信短视频）则尽量将其功能隐藏或者关闭。
2. 主动关注一些高质量的内容，取关一些没有营养的内容。
3. 抽时间读书和写读书笔记
4. 如果你有孩子，从小便要培养其独立思考的习惯！
